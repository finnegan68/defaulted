{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import decomposition\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('appl_data.csv')\n",
    "result = pd.read_csv('is_default.csv')\n",
    "on_site = pd.read_csv('behav_on_site.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Making one df\n",
    "cnt=0\n",
    "c = list(set(on_site['id_ref'].values))\n",
    "clients = list(set(on_site['client_id'].values))\n",
    "c.append('num_of_devices')\n",
    "new_onsite = pd.DataFrame(columns = c)\n",
    "\n",
    "for client in clients:\n",
    "    num_of_devices = on_site.loc[on_site['client_id'] == client].device_id.shape[0]\n",
    "    links = list(set(on_site.loc[on_site['client_id'] == client].id_ref.values))\n",
    "    row = [0] * len(c)\n",
    "    for i in range(len(c)-1):\n",
    "        if c[i] in links:\n",
    "            row[i] = 1\n",
    "    row[-1] = num_of_devices\n",
    "    new_onsite.loc[cnt] = row\n",
    "    cnt+=1\n",
    "\n",
    "val = new_onsite.values\n",
    "pca = decomposition.PCA(n_components=20)\n",
    "val = pca.fit_transform(val)\n",
    "new_onsite = pd.DataFrame(val, columns = [i for i in range(20)])\n",
    "new_onsite['client_id'] = clients\n",
    "\n",
    "df = df.merge(new_onsite, left_on='client_id', right_on='client_id')\n",
    "df = df.merge(result, left_on='appl_id', right_on='appl_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_col = ['is_same_reg_lived_since',\n",
    "           'region_reg',\n",
    "           'empl_worker_count',\n",
    "           'appl_id',\n",
    "           'app_crtime',\n",
    "           'client_id',\n",
    "           'pass_bdate', \n",
    "           'birth',\n",
    "           'lived_since',\n",
    "           'jobsworksince']\n",
    "\n",
    "df['birth'] = pd.to_datetime(df['birth'])\n",
    "df['pass_bdate'] = pd.to_datetime(df['pass_bdate'])\n",
    "df['lived_since'] = pd.to_datetime(df['lived_since'])\n",
    "df['jobsworksince'] = pd.to_datetime(df['jobsworksince'])\n",
    "\n",
    "def f1(end):\n",
    "    r = relativedelta(pd.to_datetime('now'), end) \n",
    "    return '{}'.format(r.months)\n",
    "\n",
    "def f2(end):\n",
    "    r = relativedelta(pd.to_datetime('now'), end) \n",
    "    return '{}'.format(r.years)\n",
    "\n",
    "df['jobsworksince'] = df['jobsworksince'].fillna(pd.to_datetime('now'))\n",
    "\n",
    "df['age'] = df['birth'].apply(f1)\n",
    "df['live_on_current_place_months'] = df['lived_since'].apply(f2)\n",
    "df['work_on_current_place_months'] = df['jobsworksince'].apply(f2)\n",
    "\n",
    "df = df.drop(del_col, axis=1)\n",
    "\n",
    "df['gender'] = df['gender'].replace(2,0)\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype object was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "to_one_hot = ['fam_status', 'region', 'empl_state', 'empl_type', 'education_area', 'education']\n",
    "categ_col = to_one_hot + ['gender', 'df']\n",
    "\n",
    "x = df.drop(categ_col, axis=1).values \n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df[df.drop(categ_col, axis=1).columns] = x_scaled\n",
    "\n",
    "df = pd.get_dummies(df, columns = to_one_hot)\n",
    "\n",
    "df['df'] = df['df'].replace('good',1)\n",
    "df['df'] = df['df'].replace('bad',0)\n",
    "\n",
    "data = df.loc[(df['df']==1) | (df['df']==0)]\n",
    "to_pred = df.loc[(df['df']!=1) & (df['df']!=0)]\n",
    "to_pred = to_pred.drop(['df'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.717428167206587"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LogReg\n",
    "\n",
    "X = data.drop(['df'], axis=1).values\n",
    "y = data['df'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs').fit(X_train, y_train)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, pred)\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.545981451235814\n",
      "0.7065682385276715\n",
      "0.6561464765331303\n",
      "0.7203900750726147\n",
      "0.7207196094567365\n",
      "0.7154500605346861\n",
      "0.6654184576470286\n",
      "0.7090163368621724\n"
     ]
    }
   ],
   "source": [
    "def run_classifier(clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    pred = clf.predict(X_test)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, pred)\n",
    "    return metrics.auc(fpr, tpr)\n",
    "\n",
    "classifiers = [KNeighborsClassifier(n_neighbors = 2),\n",
    "              SVC(),\n",
    "              GaussianNB(),\n",
    "              Perceptron(),\n",
    "              LinearSVC(),\n",
    "              SGDClassifier(),\n",
    "              DecisionTreeClassifier(),\n",
    "              RandomForestClassifier(n_estimators=100)]\n",
    "\n",
    "result = []\n",
    "\n",
    "for c in classifiers:\n",
    "    score = run_classifier(c)\n",
    "    result.append(score)\n",
    "    \n",
    "for score in result:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
